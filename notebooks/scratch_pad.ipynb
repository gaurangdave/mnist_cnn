{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca006c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 09:55:36.323259: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752512136.338676   19473 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752512136.343312   19473 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752512136.355741   19473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512136.355763   19473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512136.355764   19473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512136.355766   19473 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-14 09:55:36.360120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600fc475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fab2a9",
   "metadata": {},
   "source": [
    "## Simple CNN For TFJS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a39cf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">🌲 Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1752512139.472778   19473 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6055 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2e:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 09:55:40.850396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752512140.865742   19626 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752512140.870373   19626 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752512140.882142   19626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512140.882192   19626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512140.882198   19626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752512140.882201   19626 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "Conversion completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Create the simplest possible model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n",
    "\n",
    "# Save and convert\n",
    "model.save(\"minimal_model.h5\")\n",
    "!tensorflowjs_converter --input_format=keras minimal_model.h5 ./minimal_tfjs/\n",
    "\n",
    "\n",
    "tfjs.converters.save_keras_model(model, './python_converted_model')\n",
    "print(\"Conversion completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852f3857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gaurangdave/workspace/mnist_cnn/venv/bin/tensorflowjs_converter\n"
     ]
    }
   ],
   "source": [
    "!which tensorflowjs_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd80ae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-14 11:23:46.931686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752517426.953984   72058 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752517426.959702   72058 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752517426.972940   72058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517426.973010   72058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517426.973016   72058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517426.973047   72058 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "usage: TensorFlow.js model converters. [-h]\n",
      "                                       [--input_format {keras_saved_model,tf_saved_model,tf_hub,keras_keras,tf_frozen_model,keras,tfjs_layers_model}]\n",
      "                                       [--output_format {keras_saved_model,keras_keras,tfjs_graph_model,keras,tfjs_layers_model}]\n",
      "                                       [--signature_name SIGNATURE_NAME]\n",
      "                                       [--saved_model_tags SAVED_MODEL_TAGS]\n",
      "                                       [--quantize_float16 [QUANTIZE_FLOAT16]]\n",
      "                                       [--quantize_uint8 [QUANTIZE_UINT8]]\n",
      "                                       [--quantize_uint16 [QUANTIZE_UINT16]]\n",
      "                                       [--quantization_bytes {1,2}]\n",
      "                                       [--split_weights_by_layer] [--version]\n",
      "                                       [--skip_op_check]\n",
      "                                       [--strip_debug_ops STRIP_DEBUG_OPS]\n",
      "                                       [--use_structured_outputs_names USE_STRUCTURED_OUTPUTS_NAMES]\n",
      "                                       [--weight_shard_size_bytes WEIGHT_SHARD_SIZE_BYTES]\n",
      "                                       [--output_node_names OUTPUT_NODE_NAMES]\n",
      "                                       [--control_flow_v2 CONTROL_FLOW_V2]\n",
      "                                       [--experiments EXPERIMENTS]\n",
      "                                       [--metadata METADATA]\n",
      "                                       [input_path] [output_path]\n",
      "\n",
      "positional arguments:\n",
      "  input_path            Path to the input file or directory. For input format\n",
      "                        \"keras\", an HDF5 (.h5) file is expected. For input\n",
      "                        format \"tensorflow\", a SavedModel directory, frozen\n",
      "                        model file, or TF-Hub module is expected.\n",
      "  output_path           Path for all output artifacts.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --input_format {keras_saved_model,tf_saved_model,tf_hub,keras_keras,tf_frozen_model,keras,tfjs_layers_model}\n",
      "                        Input format. For \"keras\", the input path can be one\n",
      "                        of the two following formats: - A topology+weights\n",
      "                        combined HDF5 (e.g., generated with\n",
      "                        `tf_keras.model.save_model()` method). - A weights-\n",
      "                        only HDF5 (e.g., generated with Keras Model's\n",
      "                        `save_weights()` method). For \"keras_saved_model\", the\n",
      "                        input_path must point to a subfolder under the saved\n",
      "                        model folder that is passed as the argument to\n",
      "                        tf.contrib.save_model.save_keras_model(). The\n",
      "                        subfolder is generated automatically by tensorflow\n",
      "                        when saving keras model in the SavedModel format. It\n",
      "                        is usually named as a Unix epoch time (e.g.,\n",
      "                        1542212752). For \"tf\" formats, a SavedModel, frozen\n",
      "                        model, or TF-Hub module is expected.\n",
      "  --output_format {keras_saved_model,keras_keras,tfjs_graph_model,keras,tfjs_layers_model}\n",
      "                        Output format. Default: tfjs_graph_model.\n",
      "  --signature_name SIGNATURE_NAME\n",
      "                        Signature of the SavedModel Graph or TF-Hub module to\n",
      "                        load. Applicable only if input format is \"tf_hub\" or\n",
      "                        \"tf_saved_model\".\n",
      "  --saved_model_tags SAVED_MODEL_TAGS\n",
      "                        Tags of the MetaGraphDef to load, in comma separated\n",
      "                        string format. Defaults to \"serve\". Applicable only if\n",
      "                        input format is \"tf_saved_model\".\n",
      "  --quantize_float16 [QUANTIZE_FLOAT16]\n",
      "                        Comma separated list of node names to apply float16\n",
      "                        quantization. You can also use wildcard symbol (*) to\n",
      "                        apply quantization to multiple nodes (e.g.,\n",
      "                        conv/*/weights). When the flag is provided without any\n",
      "                        nodes the default behavior will match all nodes.\n",
      "  --quantize_uint8 [QUANTIZE_UINT8]\n",
      "                        Comma separated list of node names to apply 1-byte\n",
      "                        affine quantization. You can also use wildcard symbol\n",
      "                        (*) to apply quantization to multiple nodes (e.g.,\n",
      "                        conv/*/weights). When the flag is provided without any\n",
      "                        nodes the default behavior will match all nodes.\n",
      "  --quantize_uint16 [QUANTIZE_UINT16]\n",
      "                        Comma separated list of node names to apply 2-byte\n",
      "                        affine quantization. You can also use wildcard symbol\n",
      "                        (*) to apply quantization to multiple nodes (e.g.,\n",
      "                        conv/*/weights). When the flag is provided without any\n",
      "                        nodes the default behavior will match all nodes.\n",
      "  --quantization_bytes {1,2}\n",
      "                        (Deprecated) How many bytes to optionally\n",
      "                        quantize/compress the weights to. 1- and 2-byte\n",
      "                        quantizaton is supported. The default (unquantized)\n",
      "                        size is 4 bytes.\n",
      "  --split_weights_by_layer\n",
      "                        Applicable to keras input_format only: Whether the\n",
      "                        weights from different layers are to be stored in\n",
      "                        separate weight groups, corresponding to separate\n",
      "                        binary weight files. Default: False.\n",
      "  --version, -v         Show versions of tensorflowjs and its dependencies\n",
      "  --skip_op_check       Skip op validation for TensorFlow model conversion.\n",
      "  --strip_debug_ops STRIP_DEBUG_OPS\n",
      "                        Strip debug ops (Print, Assert, CheckNumerics) from\n",
      "                        graph.\n",
      "  --use_structured_outputs_names USE_STRUCTURED_OUTPUTS_NAMES\n",
      "                        TFJS graph outputs become a tensor map with the same\n",
      "                        structure as the TF graph structured_outputs (only\n",
      "                        supported for structured_outputs of the form {key1:\n",
      "                        tensor1, key2: tensor2...})\n",
      "  --weight_shard_size_bytes WEIGHT_SHARD_SIZE_BYTES\n",
      "                        Shard size (in bytes) of the weight files. Currently\n",
      "                        applicable only when output_format is\n",
      "                        tfjs_layers_model or tfjs_graph_model.\n",
      "  --output_node_names OUTPUT_NODE_NAMES\n",
      "                        The names of the output nodes, separated by commas.\n",
      "                        E.g., \"logits,activations\". Applicable only if input\n",
      "                        format is \"tf_frozen_model\".\n",
      "  --control_flow_v2 CONTROL_FLOW_V2\n",
      "                        Enable control flow v2 ops, this would improve\n",
      "                        inference performance on models with branches or\n",
      "                        loops.\n",
      "  --experiments EXPERIMENTS\n",
      "                        Enable experimental features, you should only enable\n",
      "                        this flag when using Python3 and TensorFlow nightly\n",
      "                        build.\n",
      "  --metadata METADATA   Attach user defined metadata in format\n",
      "                        key:path/metadata.json Separate multiple metadata\n",
      "                        files by comma.\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4ce962a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow-related packages: ['tensorboard', 'tensorboard-data-server', 'tensorflow', 'tensorflow-decision-forests', 'tensorflow-hub', 'tensorflowjs', 'tensorstore']\n"
     ]
    }
   ],
   "source": [
    "# Check for conflicting packages\n",
    "import pkg_resources\n",
    "installed_packages = [d.project_name for d in pkg_resources.working_set]\n",
    "tf_packages = [p for p in installed_packages if 'tensor' in p.lower()]\n",
    "print(\"TensorFlow-related packages:\", tf_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "390e1d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow.js imported successfully\n",
      "TensorFlow.js version: 4.22.0\n",
      "Available functions: ['absolute_import', 'converters', 'division', 'print_function', 'quantization', 'read_weights', 'resource_loader', 'version', 'write_weights']\n",
      "Converter imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any import issues\n",
    "try:\n",
    "    import tensorflowjs as tfjs\n",
    "    print(\"TensorFlow.js imported successfully\")\n",
    "    print(\"TensorFlow.js version:\", tfjs.__version__)\n",
    "    print(\"Available functions:\", [x for x in dir(tfjs) if not x.startswith('_')])\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "\n",
    "# Check if converter is available\n",
    "try:\n",
    "    from tensorflowjs.converters import save_keras_model\n",
    "    print(\"Converter imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Converter import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "493508c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully\n",
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "Python API conversion successful!\n",
      "Files created: ['model.json', 'group1-shard1of1.bin']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Create minimal model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='softmax', input_shape=(784,))\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "print(\"Model created successfully\")\n",
    "\n",
    "# Try Python API conversion\n",
    "try:\n",
    "    tfjs.converters.save_keras_model(model, './test_model_python')\n",
    "    print(\"Python API conversion successful!\")\n",
    "    \n",
    "    # Check if files were created\n",
    "    import os\n",
    "    if os.path.exists('./test_model_python'):\n",
    "        files = os.listdir('./test_model_python')\n",
    "        print(\"Files created:\", files)\n",
    "    else:\n",
    "        print(\"No output directory created\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Python API conversion failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf36690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as test_model.h5\n",
      "2025-07-14 11:29:46.310799: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752517786.329148   81264 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752517786.335226   81264 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752517786.350978   81264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517786.351026   81264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517786.351032   81264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752517786.351054   81264 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "\u001b[32m🌲 Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n",
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "usage: TensorFlow.js model converters. [-h]\n",
      "                                       [--input_format {keras_keras,keras,tf_frozen_model,tfjs_layers_model,tf_saved_model,keras_saved_model,tf_hub}]\n",
      "                                       [--output_format {keras_keras,tfjs_graph_model,keras,tfjs_layers_model,keras_saved_model}]\n",
      "                                       [--signature_name SIGNATURE_NAME]\n",
      "                                       [--saved_model_tags SAVED_MODEL_TAGS]\n",
      "                                       [--quantize_float16 [QUANTIZE_FLOAT16]]\n",
      "                                       [--quantize_uint8 [QUANTIZE_UINT8]]\n",
      "                                       [--quantize_uint16 [QUANTIZE_UINT16]]\n",
      "                                       [--quantization_bytes {1,2}]\n",
      "                                       [--split_weights_by_layer] [--version]\n",
      "                                       [--skip_op_check]\n",
      "                                       [--strip_debug_ops STRIP_DEBUG_OPS]\n",
      "                                       [--use_structured_outputs_names USE_STRUCTURED_OUTPUTS_NAMES]\n",
      "                                       [--weight_shard_size_bytes WEIGHT_SHARD_SIZE_BYTES]\n",
      "                                       [--output_node_names OUTPUT_NODE_NAMES]\n",
      "                                       [--control_flow_v2 CONTROL_FLOW_V2]\n",
      "                                       [--experiments EXPERIMENTS]\n",
      "                                       [--metadata METADATA]\n",
      "                                       [input_path] [output_path]\n",
      "TensorFlow.js model converters.: error: unrecognized arguments: --verbose\n"
     ]
    }
   ],
   "source": [
    "# Save model first\n",
    "model.save(\"test_model.h5\")\n",
    "print(\"Model saved as test_model.h5\")\n",
    "\n",
    "# Try conversion with verbose output\n",
    "!tensorflowjs_converter --input_format=keras --output_format=tfjs_graph_model test_model.h5 ./test_output_verbose/ --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6192decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurangdave/workspace/mnist_cnn/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to lookup keras version from the file,\n",
      "    this is likely a weight only file\n",
      "Conversion completed!\n",
      "Files created: ['model.json', 'group1-shard1of1.bin']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "# Your full model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train your model\n",
    "# model.fit(x=X_train_normalized, y=y_train_tensor, validation_data=(X_val_normalized, y_val_tensor), epochs=2)\n",
    "\n",
    "# Convert using Python API (this should work!)\n",
    "tfjs.converters.save_keras_model(model, './your_model_tfjs')\n",
    "print(\"Conversion completed!\")\n",
    "\n",
    "# Check files\n",
    "import os\n",
    "if os.path.exists('./your_model_tfjs'):\n",
    "    files = os.listdir('./your_model_tfjs')\n",
    "    print(\"Files created:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6005cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
